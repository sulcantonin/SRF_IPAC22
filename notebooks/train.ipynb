{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep One-Class Classification\n",
    "http://proceedings.mlr.press/v80/ruff18a/ruff18a.pdf\n",
    "\n",
    "Deep Semi-Supervised Anoamly Detection\n",
    "https://arxiv.org/pdf/1906.02694.pdf\n",
    "\n",
    "\n",
    "(Supervised) Contrastive Loss\n",
    "\n",
    "CSI: Novelty Detection via Contrastive Learningon Distributionally Shifted Instances : https://arxiv.org/pdf/2007.08176.pdf\n",
    "\n",
    "A Unifying Review of Deep and Shallow AnomalyDetection : https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347460&tag=1\n",
    "\n",
    "Dropout techniques on RNNs\n",
    "\n",
    "https://adriangcoder.medium.com/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuenchDetectionNetworkLSTM(\n",
      "  (input_rnn): LSTM(1092, 256, bias=False)\n",
      "  (hidden_rnn): LSTM(256, 256, bias=False)\n",
      "  (hidden_lin): Linear(in_features=256, out_features=256, bias=False)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "last epoch 0 from file ../models/LSTM_256_LSTM1_Linear1/eta_anom_1_eta_label_5_feb22_nobias_const_c/anomaly_epoch_0019\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for QuenchDetectionNetworkLSTM:\n\tMissing key(s) in state_dict: \"input_rnn.weight_ih_l0\", \"input_rnn.weight_hh_l0\", \"hidden_rnn.weight_ih_l0\", \"hidden_rnn.weight_hh_l0\", \"hidden_lin.weight\". \n\tUnexpected key(s) in state_dict: \"cnn.0.weight\", \"cnn.2.weight\", \"cnn.4.weight\", \"linear.weight\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286860/3559603276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'last epoch {last_epoch} from file {weights_file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1483\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for QuenchDetectionNetworkLSTM:\n\tMissing key(s) in state_dict: \"input_rnn.weight_ih_l0\", \"input_rnn.weight_hh_l0\", \"hidden_rnn.weight_ih_l0\", \"hidden_rnn.weight_hh_l0\", \"hidden_lin.weight\". \n\tUnexpected key(s) in state_dict: \"cnn.0.weight\", \"cnn.2.weight\", \"cnn.4.weight\", \"linear.weight\". "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "# from tsne_torch import TorchTSNE as TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from math import ceil\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "sys.path.insert(0, '../code/')\n",
    "sys.path.insert(0, './models/')\n",
    "import util\n",
    "from models import *\n",
    "import dataset\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower\n",
    "\n",
    "t2n = lambda x : x.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "titles = ['PROBE.AMPL.TD', 'PROBE.PHASE.TD', \\\n",
    "          'VFORW.AMPL.TD', 'VFORW.PHASE.TD', \\\n",
    "          'VREFL.AMPL.TD', 'VREFL.PHASE.TD']\n",
    "\n",
    "parameters = {\n",
    "    'input_dims' : [0,1,2,3,4,5],\n",
    "    # 'input_dims' : [0,2,4],\n",
    "    'num_epochs' : 128,\n",
    "    'learning_rate' : 0.001,\n",
    "    'weight_decay' : 10e-4,\n",
    "    'eta_anom' : 1.0,\n",
    "    'eta_label' : 5.0,\n",
    "    'eta_network' : 0, # 1/2\n",
    "    'n_batches' : 32,\n",
    "    'test_batches': 3,\n",
    "    'num_hidden' : 256,\n",
    "    'num_hidden_layers' : 1}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#\n",
    "#\n",
    "# --- NETWORK & OPTIM ---\n",
    "#\n",
    "\n",
    "'''\n",
    "# regular\n",
    "model = QuenchDetectionNetworkLSTM(parameters['num_hidden'],\n",
    "                                   parameters['num_hidden_layers'],\n",
    "                                   parameters['eta_anom'], \n",
    "                                   parameters['eta_label'], \n",
    "                                   parameters['eta_network'],\n",
    "                                   len(parameters['input_dims'])).to(device)\n",
    "model.c = model.c.to(device)\n",
    "folder = '../models/LSTM_256_LSTM1_Linear1/eta_anom_1_eta_label_5_feb22_2/'\n",
    "\n",
    "'''\n",
    "# linear beteween\n",
    "'''\n",
    "model = QuenchDetectionNetworkLSTM2LinearBetween(num_hidden = parameters['num_hidden'],\n",
    "                                   num_hidden_layers = parameters['num_hidden_layers'],\n",
    "                                   eta_anom = parameters['eta_anom'], \n",
    "                                   eta_label = parameters['eta_label'], \n",
    "                                   eta_network = parameters['eta_network']).to(device)\n",
    "folder = '../models/LSTM_256_LSTM2_Linear1_LinearBetween/eta_anom_1_eta_label_5/'\n",
    "'''\n",
    "\n",
    "# layer norm.  \n",
    "'''\n",
    "model = QuenchDetectionNetworkLSTM2LayerNorm(num_hidden = parameters['num_hidden'],\n",
    "                                   num_hidden_layers = parameters['num_hidden_layers'],\n",
    "                                   eta_anom = parameters['eta_anom'], \n",
    "                                   eta_label = parameters['eta_label'], \n",
    "                                   eta_network = parameters['eta_network']).to(device)\n",
    "folder = '../models/LSTM_256_LSTM2_Linear1_LayerNorm/eta_anom_1_eta_label_5/'\n",
    "'''\n",
    "\n",
    "# softmax loss - i.e. a regular classifier\n",
    "'''\n",
    "model = QuenchDetectionNetworkClassifierLSTM(num_hidden = parameters['num_hidden'],\n",
    "                                   num_hidden_layers = parameters['num_hidden_layers'],\n",
    "                                   eta_anom = parameters['eta_anom'], \n",
    "                                   eta_label = parameters['eta_label'], \n",
    "                                   eta_network = parameters['eta_network']).to(device)\n",
    "folder = '../models/LSTM_256_LSTM1_Linear1_Classifier/eta_anom_1_eta_label_5_2(same as OC)_2/'\n",
    "'''\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    print(f'creating {folder}')\n",
    "    os.makedirs(folder)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=parameters['learning_rate'], weight_decay = parameters['weight_decay'])\n",
    "print(model)\n",
    "last_epoch = 0\n",
    "\n",
    "weights_file = sorted(glob(folder + 'anomaly_epoch_0*'))[-1]\n",
    "print(f'last epoch {last_epoch} from file {weights_file}')\n",
    "last_epoch = int(weights_file.split('_')[-1])\n",
    "model.load_state_dict(torch.load(weights_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file /home/sulcan/data/quench/X_down_labelled_all.pickle exists, loading file\n",
      "file /home/sulcan/data/quench/X_down_labelled_all.pickle loaded\n",
      "file /home/sulcan/data/quench/X_up_2021-08_all.pickle exists, loading file\n",
      "file /home/sulcan/data/quench/X_up_2021-08_all.pickle loaded\n",
      "file /home/sulcan/data/quench/X_up_2021-10_all.pickle exists, loading file\n",
      "file /home/sulcan/data/quench/X_up_2021-10_all.pickle loaded\n",
      "file /home/sulcan/data/quench/X_up_2021-11_all.pickle exists, loading file\n",
      "file /home/sulcan/data/quench/X_up_2021-11_all.pickle loaded\n",
      "file /home/sulcan/data/quench/X_up_2022-01_all.pickle exists, loading file\n",
      "file /home/sulcan/data/quench/X_up_2022-01_all.pickle loaded\n",
      "file /home/sulcan/data/quench/X_up_2022-02_all.pickle exists, loading file\n",
      "file /home/sulcan/data/quench/X_up_2022-02_all.pickle loaded\n"
     ]
    }
   ],
   "source": [
    "faulty_folders = ['/home/sulcan/data/quench/down_labelled/']\n",
    "faulty_files = ['/home/sulcan/data/quench/X_down_labelled_all.pickle']\n",
    "# faulty_files = ['/home/sulcan/data/quench/X_down_labelled_classified_all.pickle']\n",
    "\n",
    "healthly_files =   ['/home/sulcan/data/quench/X_up_2021-08_all.pickle',\n",
    "                    '/home/sulcan/data/quench/X_up_2021-10_all.pickle', \n",
    "                    '/home/sulcan/data/quench/X_up_2021-11_all.pickle',\n",
    "                    '/home/sulcan/data/quench/X_up_2022-01_all.pickle',\n",
    "                    '/home/sulcan/data/quench/X_up_2022-02_all.pickle'\n",
    "                   ]\n",
    "\n",
    "healthly_folders = [None] * len(healthly_files) # using [None] causes an exception in case of an error in path and prevent the mundane processing the existing files\n",
    "\n",
    "X_faulty, files_and_locations_faulty, pids_faulty = dataset.load_multiple_data_from_numpy(faulty_files, faulty_folders, parameters['input_dims'])\n",
    "X_healthly, files_and_locations_healthly, pids_healthly = dataset.load_multiple_data_from_numpy(healthly_files, healthly_folders, parameters['input_dims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out empty healthly events 81922\n",
      "Remaining healthly events 81922\n",
      "Filtering out empty faulty events 1331\n",
      "Remaining faulty events 1331\n"
     ]
    }
   ],
   "source": [
    "crit = lambda x : x.shape[-1] > 0\n",
    "print(f'Filtering out empty healthly events {len(X_healthly)}')\n",
    "X_healthly = list(filter(crit, X_healthly))\n",
    "print(f'Remaining healthly events {len(X_healthly)}')\n",
    "\n",
    "print(f'Filtering out empty faulty events {len(X_faulty)}')\n",
    "X_faulty = list(filter(crit, X_faulty))\n",
    "print(f'Remaining faulty events {len(X_faulty)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2058be78f271459cabf80302751021f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047b608aa3e742838293c8616b8299ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthly 81922 faulty 1331\n"
     ]
    }
   ],
   "source": [
    "# --- putting everything together into an input----\n",
    "input = X_healthly + X_faulty\n",
    "\n",
    "# (A,P) -> (I,Q)\n",
    "if len(parameters['input_dims']) == 6: \n",
    "    input = dataset.transform_RF_pulses(input)\n",
    "# just selecting subset of values\n",
    "elif len(parameters['input_dims']) == 3:\n",
    "    input = dataset.select_dimensions(input,parameters['input_dims'])\n",
    "input = dataset.normalize_data(input)\n",
    "\n",
    "# --- creating labels ----\n",
    "labels = [+1] * len(X_healthly) + [-1] * len(X_faulty)\n",
    "\n",
    "print(f'healthly {len(X_healthly)} faulty {len(X_faulty)}')\n",
    "\n",
    "del X_faulty\n",
    "del X_healthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading permutation\n",
      "number of faults in first batch 33\n"
     ]
    }
   ],
   "source": [
    "# permutation for batch indices\n",
    "if os.path.isfile(folder + '/permutation.npy'):\n",
    "    print('loading permutation')\n",
    "    permutation = np.load(folder + '/permutation.npy', allow_pickle = True)\n",
    "else:\n",
    "    print('creating permutation & saving it')\n",
    "    permutation = dataset.generate_permutation_for_batch_indices(input, parameters['n_batches'])\n",
    "    np.save(folder + '/permutation.npy',permutation)\n",
    "\n",
    "with open(folder + 'training_data.pickle','wb') as f:\n",
    "    pickle.dump({'healthly_files' : healthly_files, \\\n",
    "                 'faulty_files' : faulty_files, \\\n",
    "                 'files_and_locations_healthly' : files_and_locations_healthly, \n",
    "                 'files_and_locations_faulty' : files_and_locations_faulty}, f)\n",
    "\n",
    "# we should make sure that the first batch has a certain number of faults\n",
    "print('number of faults in first batch', np.sum([labels[i] == -1 for i in permutation[0]]))\n",
    "\n",
    "assert len(set([i for p in permutation for i in p])) == len(input)\n",
    "assert len(input) == len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' TODO '''\n",
    "\n",
    "class QuenchDetectionNetworkCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuenchDetectionNetworkCNN,self).__init__()\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(6,8,8,stride = 1, bias = False),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(8,16, 8,stride = 1, bias = False),\n",
    "                              nn.ReLU(),\n",
    "                              nn.Conv2d(16,32,8,stride = 1, bias = False))\n",
    "        self.linear = nn.Linear(320, 16, bias = False)\n",
    "        self.c = torch.randn(1,16)    \n",
    "    \n",
    "    def phi(self, x):\n",
    "        \n",
    "        # filtering out too short sequences\n",
    "        lengths = torch.tensor([x_.shape[0] for x_ in x])\n",
    "        x = [x[i] for i in torch.where(lengths > 64)[0]]\n",
    "        # the calculation itself, cnn first\n",
    "        x = [x.reshape((-1,6,182)).transpose(1,0).unsqueeze(0) for x in x]\n",
    "        # then summing out all sequences, different kernels should also be tried (maybe max?)\n",
    "        x = torch.cat([self.cnn(x).sum(dim = 2).reshape((1,-1)) for x in x])\n",
    "        print(x[0].shape)\n",
    "        # linear output\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.phi(x)\n",
    "        return torch.linalg.vector_norm(x - self.c,dim = -1), x\n",
    "\n",
    "    def loss(self, D,L):\n",
    "        s, _ = self.forward(D)\n",
    "        print(s ** L)\n",
    "        return None\n",
    "    \n",
    "model = QuenchDetectionNetworkCNN().to(device)\n",
    "model.c = model.c.to(device)\n",
    "# model.loss(D,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601\n"
     ]
    }
   ],
   "source": [
    "print(len(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5152])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2574x5152 and 320x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286860/1221024451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_286860/69833820.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_286860/69833820.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# linear output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2574x5152 and 320x16)"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    res = model(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_R = []\n",
    "losses_D = []\n",
    "losses_W = []\n",
    "\n",
    "for epoch in range(last_epoch+1, parameters['num_epochs']):\n",
    "    for batch in range(parameters['test_batches'],parameters['n_batches']):\n",
    "        indices = permutation[batch]\n",
    "        N = len(indices)\n",
    "        \n",
    "        # input data\n",
    "        D = [torch.tensor(input[i]).to(device) for i in indices]\n",
    "        # L == -1 # (-1) quench\n",
    "        # L == +1 # (+1) proper\n",
    "        L = torch.stack([torch.tensor(labels[i]).to(device) for i in indices]).float().flatten()\n",
    "        break\n",
    "        # ===================forward=====================        \n",
    "        loss_R, loss_D, loss_W = model.loss(D,L)\n",
    "        loss = loss_R + loss_D + loss_W\n",
    "        \n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'LOSS (epoch {epoch},batch {batch}) {loss.item()} = R({loss_R.item()}) + D({loss_D.item()}) + W({loss_W.item()})')\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        losses_R.append(loss_R.item())\n",
    "        losses_D.append(loss_D.item())\n",
    "        losses_W.append(loss_W.item())\n",
    "    break\n",
    "    plt.plot(losses,'b')\n",
    "    plt.plot(losses_R,'g')\n",
    "    plt.plot(losses_D,'r')\n",
    "    plt.plot(losses_W,'c')\n",
    "    plt.show()\n",
    "    torch.save(model.state_dict(),folder + '/anomaly_epoch_' + str(epoch).zfill(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
